{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6d87d5",
   "metadata": {},
   "source": [
    "\n",
    "# EDA — MIT-BIH Arrhythmia (AAMI)\n",
    "**Proyecto:** *Clasificación explicable de arritmias cardíacas a partir de electrocardiogramas transformados en espectrogramas mediante redes neuronales convolucionales*\n",
    "\n",
    "**Dataset:** MIT-BIH Arrhythmia Database (Kaggle).  \n",
    "**Objetivo:** EDA completo + estandarización AAMI (N, S, V, F, Q).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7451651-c857-4eb8-a61a-a6cbd4f17f77",
   "metadata": {},
   "source": [
    "# EDA — MIT-BIH Arrhythmia Database\n",
    "\n",
    "## Descripción del Proyecto\n",
    "Este notebook realiza un **Análisis Exploratorio de Datos (EDA)** sobre el dataset **MIT-BIH Arrhythmia Database**.\n",
    "\n",
    "- **Nombre del proyecto**: Clasificación de arritmias cardíacas\n",
    "- **Dataset**: MIT-BIH Arrhythmia (señales y anotaciones de ECG)\n",
    "- **Objetivo del EDA**: Identificar patrones y anomalías en las señales de ECG que permitan guiar el desarrollo de un modelo de IA para la clasificación de arritmias.\n",
    "\n",
    "## Objetivos Específicos\n",
    "1. Explorar y comprender la estructura del dataset.\n",
    "2. Analizar distribuciones univariadas y bivariadas de las variables.\n",
    "3. Detectar correlaciones entre variables relevantes.\n",
    "4. Identificar patrones multivariados y posibles anomalías.\n",
    "5. Extraer **insights** que orienten el preprocesamiento y modelado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf08c2-8a3f-409f-bd88-be4308de0b7d",
   "metadata": {},
   "source": [
    "# Explicación del Dataset MIT-BIH\n",
    "\n",
    "Contexto\n",
    "El dataset proviene del **MIT-BIH Arrhythmia Database**, un estándar en cardiología computacional para el diagnóstico automático de arritmias.  \n",
    "Contiene registros de **electrocardiogramas (ECG)** tomados con monitores Holter a 360 Hz, con 2 derivaciones principales y anotaciones clínicas realizadas por cardiólogos.\n",
    "\n",
    "## Variables del Dataset\n",
    "\n",
    "#### Señales de ECG (features)\n",
    "Los nombres de columnas como **`MLII`, `V1`, `V2`, `V4`, `V5`, `V6`** corresponden a **derivaciones estándar del electrocardiograma**:\n",
    "\n",
    "- **MLII (Lead II modificado):** derivación más usada en el MIT-BIH, muy informativa para detectar arritmias.  \n",
    "- **V1, V2, V4, V5, V6:** derivaciones precordiales colocadas en distintas posiciones del pecho, capturan la actividad eléctrica del corazón desde diferentes ángulos.\n",
    "\n",
    "Estas variables representan las **señales crudas de ECG** que servirán como entrada al modelo de IA.\n",
    "\n",
    "#### Variable objetivo (`type`)\n",
    "La columna **`type`** contiene las etiquetas que clasifican cada latido, anotadas por cardiólogos.  \n",
    "Se siguen las categorías de la **AAMI (Association for the Advancement of Medical Instrumentation):**\n",
    "\n",
    "- **N:** Latido normal (Normal beat).  \n",
    "- **S:** Latido supraventricular ectópico (ej. prematuro auricular).  \n",
    "- **V:** Latido ventricular ectópico (ej. PVC).  \n",
    "- **F:** Latido de fusión (mezcla entre normal y ventricular).  \n",
    "- **Q:** Latidos no clasificables o desconocidos.  \n",
    "\n",
    "\n",
    "\n",
    "## Relación entre variables\n",
    "\n",
    "| Variables (`features`) | Qué representan | Uso |\n",
    "|-------------------------|-----------------|-----|\n",
    "| `MLII`, `V1`, `V2`, `V4`, `V5`, `V6` | Señales crudas de ECG en distintas derivaciones | Entrada (input) al modelo |\n",
    "| `type` | Clase del latido (N, S, V, F, Q) | Salida (target) del modelo |\n",
    "\n",
    "\n",
    "## Implicaciones para el modelo\n",
    "- El modelo debe aprender a **mapear patrones en las señales de ECG** hacia una clasificación en `type`.  \n",
    "- Los *features* pueden provenir de:\n",
    "  - **Señales crudas:** ventanas de ECG alrededor de cada latido.  \n",
    "  - **Features handcrafted:** amplitudes, duración de ondas QRS, intervalos RR, etc.  \n",
    "  - **Transformaciones:** wavelets, espectrogramas o embeddings generados con redes neuronales (CNN/RNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de812b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) instala faltantes\n",
    "%pip install statsmodels pingouin numpy pandas matplotlib seaborn scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317bc3c",
   "metadata": {},
   "source": [
    "## Importación de librerías y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23032442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "except Exception:\n",
    "    sm = None\n",
    "    multipletests = None\n",
    "    warnings.warn(\"statsmodels no disponible; se continuará sin algunas pruebas.\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(\"Versions -> pandas:\", pd.__version__, \"| numpy:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5137987",
   "metadata": {},
   "source": [
    "## 1) Carga de datos y exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b355259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuración\n",
    "DATA_DIR = Path(r\"C:\\Users\\luisa\\Documents\\Titulacion_UEES\\Notebooks\\EDA-MIT-BIH-Arrhythmia-Database\\kaggle_dataset\")\n",
    "FS = 360  # Hz\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    candidates = []\n",
    "    for p in Path(\".\").rglob(\"*\"):\n",
    "        try:\n",
    "            if p.is_dir():\n",
    "                has_csv = any(Path(p).glob(\"[0-9][0-9][0-9].csv\"))\n",
    "                has_ann = any(Path(p).glob(\"[0-9][0-9][0-9]annotations.txt\"))\n",
    "                if has_csv and has_ann:\n",
    "                    candidates.append(p)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if candidates:\n",
    "        DATA_DIR = candidates[0]\n",
    "        print(\"DATA_DIR auto-detectado en:\", DATA_DIR.resolve())\n",
    "    else:\n",
    "        print(\"⚠️ Ajusta DATA_DIR manualmente.\")\n",
    "\n",
    "DATA_DIR = DATA_DIR.resolve()\n",
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a196260",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lectores y utilidades\n",
    "def _clean_signal_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # normaliza nombres de columnas y tipos para CSV de señales\n",
    "    df = df.copy()\n",
    "    df.columns = [c.replace(\"'\", \"\").strip() for c in df.columns]\n",
    "    rename_map = {}\n",
    "    for c in df.columns:\n",
    "        cc = c.lower().replace(\" \", \"\").replace(\"#\", \"\")\n",
    "        if cc == \"sample\":\n",
    "            rename_map[c] = \"sample\"\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "    for c in list(df.columns):\n",
    "        clean = c.strip().upper().replace(\" \", \"\")\n",
    "        if clean in (\"MLII\", \"ML2\"):\n",
    "            df = df.rename(columns={c: \"MLII\"})\n",
    "        elif clean in (\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"):\n",
    "            df = df.rename(columns={c: clean})\n",
    "    if \"sample\" not in df.columns:\n",
    "        raise RuntimeError(\"El archivo de señales no contiene 'sample'.\")\n",
    "    for c in df.columns:\n",
    "        if c != \"type\":\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    canal_cols = [col for col in df.columns if col in (\"MLII\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\")]\n",
    "    df = df.dropna(subset=[\"sample\"], how=\"any\")\n",
    "    if canal_cols:\n",
    "        df = df.dropna(subset=canal_cols, how=\"all\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['sample'] = df['sample'].astype(int)\n",
    "    df['time_sec'] = df['sample'] / FS\n",
    "    if 'type' in df.columns:\n",
    "        df['type'] = df['type'].astype(str).str.strip().replace('', np.nan).astype('category')\n",
    "    return df\n",
    "\n",
    "def read_signal_csv(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return _clean_signal_df(df)\n",
    "\n",
    "def read_annotations_txt(ann_path: Path) -> pd.DataFrame:\n",
    "    colnames = ['Time','sample','type','Sub','Chan','Num','Aux']\n",
    "    try:\n",
    "        df = pd.read_fwf(ann_path, names=colnames, header=0)\n",
    "    except Exception:\n",
    "        df = pd.read_csv(ann_path, sep=r\"\\\\s+\", engine='python', names=colnames, header=0)\n",
    "    df['sample'] = pd.to_numeric(df['sample'], errors='coerce')\n",
    "    df = df.dropna(subset=['sample']).reset_index(drop=True)\n",
    "    df['sample'] = df['sample'].astype(int)\n",
    "    df['type'] = df['type'].astype(str).str.strip()\n",
    "    df = df[df['type'] != \"\"].reset_index(drop=True)\n",
    "    df['type'] = df['type'].astype('category')\n",
    "    try:\n",
    "        pd.to_timedelta(df['Time'])\n",
    "        df['time_sec'] = pd.to_timedelta(df['Time']).dt.total_seconds()\n",
    "    except Exception:\n",
    "        df['time_sec'] = df['sample'] / FS\n",
    "    for col in ['Sub','Chan','Num','Aux']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    return df[['sample','type','Sub','Chan','Num','Aux','time_sec']].copy()\n",
    "\n",
    "def list_record_ids(base_dir: Path = DATA_DIR, min_records: int = 1) -> List[str]:\n",
    "    ids = sorted(p.stem for p in base_dir.glob(\"[0-9][0-9][0-9].csv\"))\n",
    "    if len(ids) < min_records:\n",
    "        raise RuntimeError(f\"Se encontraron {len(ids)} registros en {base_dir}.\")\n",
    "    return ids\n",
    "\n",
    "def load_record(record_id: str, base_dir: Path = DATA_DIR) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    csv_path = base_dir / f\"{record_id}.csv\"\n",
    "    ann_path = base_dir / f\"{record_id}annotations.txt\"\n",
    "    sig = read_signal_csv(csv_path)\n",
    "    ann = read_annotations_txt(ann_path)\n",
    "    sig['record'] = str(record_id)\n",
    "    ann['record'] = str(record_id)\n",
    "    sig = sig.merge(ann[['sample','type']], on='sample', how='left')\n",
    "    sig['type'] = pd.Categorical(sig['type'])\n",
    "    return sig, ann\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bac4e7",
   "metadata": {},
   "source": [
    "### Estandarización a AAMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93581597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AAMI_MAP = {\n",
    "    'N':'N','L':'N','R':'N','e':'N','j':'N',        # N\n",
    "    'A':'S','a':'S','J':'S','S':'S',                # S\n",
    "    'V':'V','E':'V',                                # V\n",
    "    'F':'F',                                        # F\n",
    "    'P':'Q','f':'Q','Q':'Q','?':'Q','/':'Q','~':'Q','|':'Q','x':'Q'  # Q/otros\n",
    "}\n",
    "def to_aami(beat_symbol: str) -> str:\n",
    "    if pd.isna(beat_symbol):\n",
    "        return np.nan\n",
    "    b = str(beat_symbol).strip()\n",
    "    return AAMI_MAP.get(b, 'Q')\n",
    "\n",
    "def add_aami_labels(df_ann: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_ann.copy()\n",
    "    df['aami'] = df['type'].astype(str).map(to_aami).astype('category')\n",
    "    return df\n",
    "\n",
    "ids = list_record_ids(DATA_DIR)\n",
    "print(\"Registros detectados:\", ids[:10], \"… total:\", len(ids))\n",
    "\n",
    "sig_0, ann_0 = load_record(ids[0])\n",
    "ann_0 = add_aami_labels(ann_0)\n",
    "display(ann_0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcafa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Señal:\", sig_0.shape, \"| columnas:\", sig_0.columns.tolist())\n",
    "print(\"Anotaciones:\", ann_0.shape, \"| columnas:\", ann_0.columns.tolist())\n",
    "\n",
    "display(sig_0.head(3)); display(sig_0.tail(3))\n",
    "display(ann_0.head(10))\n",
    "\n",
    "print(\"\\nInfo de señales:\")\n",
    "display(sig_0.info())\n",
    "\n",
    "print(\"\\nValores faltantes (señal):\")\n",
    "display(sig_0.isna().sum())\n",
    "\n",
    "print(\"\\nResumen estadístico (señal):\")\n",
    "display(sig_0.describe().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd55c50",
   "metadata": {},
   "source": [
    "### Dataset latido-a-latido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afacfd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_beats_dataframe(record_ids: List[str], base_dir: Path = DATA_DIR, win_ms: int = 100) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    half_win = int((win_ms/1000.0) * FS / 2)\n",
    "    for rid in record_ids:\n",
    "        sig, ann = load_record(rid, base_dir)\n",
    "        ann = add_aami_labels(ann)\n",
    "        channel_cols = [c for c in sig.columns if c in (\"MLII\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\")]\n",
    "        sig_idx = sig.set_index('sample')\n",
    "        for _, a in ann.iterrows():\n",
    "            s = int(a['sample'])\n",
    "            rec = {'record': rid, 'sample': s, 'time_sec': a['time_sec'],\n",
    "                   'type': str(a['type']), 'aami': str(a['aami'])}\n",
    "            for ch in channel_cols:\n",
    "                rec[f'{ch}_val'] = sig_idx.loc[s, ch] if s in sig_idx.index else np.nan\n",
    "            lo, hi = s - half_win, s + half_win\n",
    "            win = sig_idx.loc[lo:hi, channel_cols] if (lo in sig_idx.index and hi in sig_idx.index) else None\n",
    "            if win is not None and len(win) > 1:\n",
    "                for ch in channel_cols:\n",
    "                    rec[f'{ch}_mean'] = float(win[ch].mean())\n",
    "                    rec[f'{ch}_std']  = float(win[ch].std())\n",
    "            rows.append(rec)\n",
    "    dfb = pd.DataFrame(rows)\n",
    "    for c in ['record','type','aami']:\n",
    "        if c in dfb.columns:\n",
    "            dfb[c] = dfb[c].astype('category')\n",
    "    return dfb\n",
    "\n",
    "n_ids = min(10, len(ids))\n",
    "beats_df = build_beats_dataframe(ids[:n_ids])\n",
    "print(beats_df.shape)\n",
    "display(beats_df.head())\n",
    "display(beats_df['aami'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87e89a",
   "metadata": {},
   "source": [
    "## 2) Análisis Univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ad3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_cols = [c for c in beats_df.columns if any(s in c for s in ['_val','_mean','_std'])]\n",
    "desc = beats_df[num_cols].describe().T\n",
    "desc['coef_var'] = desc['std'] / desc['mean'].replace(0, np.nan)\n",
    "display(desc.head(20))\n",
    "\n",
    "col_example = next((c for c in num_cols if c.endswith('_val')), num_cols[0])\n",
    "fig, ax = plt.subplots(); ax.hist(beats_df[col_example].dropna(), bins=50)\n",
    "ax.set_title(f'Histograma: {col_example}'); ax.set_xlabel(col_example); ax.set_ylabel('Frecuencia'); plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(); ax.boxplot(beats_df[col_example].dropna(), vert=True)\n",
    "ax.set_title(f'Boxplot: {col_example}'); ax.set_ylabel(col_example); plt.show()\n",
    "\n",
    "z = np.abs(stats.zscore(beats_df[num_cols].dropna(), nan_policy='omit'))\n",
    "outlier_mask = (z > 3).any(axis=1)\n",
    "print(\"Outliers (Z>3):\", int(outlier_mask.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_counts = beats_df['aami'].value_counts().sort_values(ascending=False)\n",
    "display(cat_counts)\n",
    "(cat_counts / cat_counts.sum()).plot(kind='bar', title='Distribución de clases AAMI')\n",
    "plt.xlabel('Clase AAMI'); plt.ylabel('Proporción'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4617d478-3f61-46ef-80d5-8e828083e123",
   "metadata": {},
   "source": [
    "- Variables numéricas: histogramas y boxplots de '*_val*' (p. ej., MLII_val, V5_val).\n",
    "- Estadísticas de distribución: media/mediana/moda (desde describe y visualizaciones).\n",
    "-  Outliers: visualizados en boxplots; consistentes con artefactos/latidos ectópicos.\n",
    "-  Variables categóricas: barras de frecuencia/proporción por clase AAMI (N, S, V, F, Q).\n",
    "Hallazgos: distribuciones unimodales con colas; presencia de outliers; desbalance marcado (N≫S,V; F,Q marginales).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86106b64",
   "metadata": {},
   "source": [
    "## 3) Análisis Bivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51262a5e-f086-4448-8d25-22398aa65081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Solo columnas de valor crudo ===\n",
    "val_cols = [c for c in beats_df.columns if c.endswith('_val')]\n",
    "if len(val_cols) < 2:\n",
    "    raise ValueError(\"No hay suficientes columnas *_val para correlación/scatter.\")\n",
    "\n",
    "# Quita filas totalmente vacías en esas columnas\n",
    "X = beats_df[val_cols].dropna(how='all')\n",
    "\n",
    "# --- Heatmap de correlación (Pearson) SOLO con *_val ---\n",
    "corr = X.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, annot=False)\n",
    "plt.title('Matriz de correlación (solo *_val)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Scatter entre dos columnas *_val (ejemplo) ---\n",
    "xcol, ycol = val_cols[0], val_cols[1]\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(beats_df[xcol], beats_df[ycol], alpha=0.3)\n",
    "plt.title(f'{xcol} vs {ycol}')\n",
    "plt.xlabel(xcol); plt.ylabel(ycol)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Boxplot de una columna *_val por clase AAMI (sin estadísticas) ---\n",
    "col_example = val_cols[0]\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "cats = beats_df['aami'].cat.categories if hasattr(beats_df['aami'], 'cat') else sorted(beats_df['aami'].dropna().unique())\n",
    "groups = [beats_df.loc[beats_df['aami'] == k, col_example].dropna() for k in cats]\n",
    "ax.boxplot(groups, labels=list(cats))\n",
    "ax.set_title(f'{col_example} por clase AAMI')\n",
    "ax.set_xlabel('Clase AAMI'); ax.set_ylabel(col_example)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0188c-b3fe-497f-a60c-3f73d276d205",
   "metadata": {},
   "source": [
    "- Matriz de correlación (Pearson) usando solo columnas '*_val*'.\n",
    "- Scatter plots entre variables '*_val*' para evaluar relaciones y posible separación por clase (recomendado colorear por 'aami').\n",
    "- Boxplots de '*_val*' por clase AAMI para observar diferencias de medianas/variabilidad.\n",
    "- Análisis con variable objetivo: diferencias por clase observables visualmente.\n",
    "Hallazgos: correlaciones bajas–moderadas (MLII vs V5) sin multicolinealidad; diferencias por clase visibles en boxplots (V suele mostrar mayor variabilidad).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c7457",
   "metadata": {},
   "source": [
    "## 4) Análisis multivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8577ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo *_val para evitar medias/std\n",
    "val_cols = [c for c in beats_df.columns if c.endswith('_val')]\n",
    "x, y = val_cols[0], val_cols[1]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(beats_df[x], beats_df[y], alpha=0.3, s=10)\n",
    "plt.title(f'{x} vs {y}')\n",
    "plt.xlabel(x); plt.ylabel(y)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871aa801",
   "metadata": {},
   "source": [
    "## 5) Detección de anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b13c7-2d70-4fff-92e1-417c95c341fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1) Distribución por clase (AAMI)\n",
    "# ============================\n",
    "ax = beats_df['aami'].value_counts().sort_index().plot(kind='bar', figsize=(6,4))\n",
    "ax.set_title('Distribución de latidos por clase AAMI')\n",
    "ax.set_xlabel('Clase AAMI'); ax.set_ylabel('Conteos')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2) Conteos cada 10s (un solo registro), leyenda = clases\n",
    "# ============================\n",
    "df = beats_df.copy()\n",
    "\n",
    "# tiempo relativo por registro (arranca en 0 s)\n",
    "df['t_rel_s'] = df.groupby('record')['time_sec'].transform(lambda s: s - s.min())\n",
    "\n",
    "# bin de 10s (0, 10, 20, ...)\n",
    "df['bin_10s'] = (df['t_rel_s'] // 10).astype(int) * 10\n",
    "\n",
    "# elige un registro (el primero)\n",
    "rid = str(df['record'].astype(str).iloc[0])\n",
    "\n",
    "# tabla de conteos por bin y clase\n",
    "cur = (df[df['record'].astype(str) == rid]\n",
    "       .groupby(['bin_10s','aami']).size()\n",
    "       .rename('count').reset_index())\n",
    "\n",
    "# pivot para graficar: filas = tiempo (seg), columnas = clase\n",
    "plot_df = cur.pivot(index='bin_10s', columns='aami', values='count').fillna(0)\n",
    "\n",
    "ax = plot_df.plot(figsize=(10,4))\n",
    "ax.set_title(f'Conteos cada 10s por clase — record {rid}')\n",
    "ax.set_xlabel('Tiempo (segundos)'); ax.set_ylabel('Conteos')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ebe63-83b3-4a97-8cca-6bac6d92ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cols = [c for c in beats_df.columns if c.endswith('_val')]\n",
    "col_example = val_cols[0]\n",
    "beats_df[[col_example]].boxplot(figsize=(5,4))\n",
    "plt.title(f'Boxplot de {col_example} (IQR y outliers)')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74f5b8-5c0a-4a9b-8e58-979ac56443d3",
   "metadata": {},
   "source": [
    "- Detección de outliers: lectura visual mediante boxplots; opcionalmente IQR para conteo.\n",
    "- Patrones temporales: conteos por bins de 10 s con tiempo relativo por 'record' y columnas = clases AAMI.\n",
    "- Distribuciones anómalas/inconsistencias: revisión de colas y segmentos con actividad S/V intensa.\n",
    "Hallazgos: episodios temporales con picos de S/V; recomendable muestreo estratificado por segmentos activos para balancear ventanas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb8315",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Conclusiones e *insights*\n",
    "## Hallazgos principales\n",
    "\n",
    "- Se identificó un **desbalance severo** en la distribución de clases AAMI: la clase **N** predomina ampliamente, mientras que las clases **S** y **V** aparecen en menor proporción, y **F** y **Q** son marginales.\n",
    "- Las **correlaciones entre canales crudos** (como MLII y V5) fueron **bajas a moderadas**, sin evidencia de colinealidad fuerte, lo que permite su combinación o tratamiento independiente.\n",
    "- Las señales crudas mostraron **distribuciones unimodales con colas largas y presencia de outliers**, lo cual sugiere artefactos, deriva de línea base o eventos fisiológicos atípicos (p. ej., latidos ectópicos).\n",
    "- El análisis temporal por bloques de 10 segundos reveló **episodios localizados de actividad S/V**, evidenciando una distribución **no estacionaria** a lo largo del registro.\n",
    "- Se validó el correcto **mapeo de anotaciones MIT-BIH a clases AAMI** (N, S, V, F, Q), así como la estandarización de la frecuencia de muestreo (360 Hz).\n",
    "\n",
    "\n",
    "## Implicaciones para el modelado (CNN + espectrogramas + XAI)\n",
    "\n",
    "- El **desbalance de clases** obliga a emplear estrategias como **ponderación por clase**, **muestreo estratificado por registro** y enfoques cuidadosos de augmentación.\n",
    "- Se observaron **diferencias en amplitud y variabilidad entre clases** en los valores crudos, lo que justifica una **normalización por ventana** previa a la extracción espectral (STFT/CWT).\n",
    "- La dinámica episódica de S/V sugiere que el muestreo de entrenamiento debe enfocarse en **ventanas representativas** de esas clases para evitar sobreajuste a N.\n",
    "- La baja colinealidad entre MLII y V5 permite la **entrada multi-canal** en modelos CNN, ya sea apilando canales o mediante fusión posterior.\n",
    "- Para la explicación de decisiones (XAI), se propone el uso de **Grad-CAM o Integrated Gradients** sobre espectrogramas log-power, permitiendo **localizar bandas temporales relevantes por clase**.\n",
    "\n",
    "\n",
    "## Recomendaciones de preprocesamiento\n",
    "\n",
    "1. **Filtrado y detrending**: aplicar filtros pasa-banda (0.5–40 Hz), eliminación de ruido de red (50/60 Hz si aplica), y corrección de la línea base.\n",
    "2. **Normalización por ventana**: usar z-score o métodos robustos (mediana/IQR), evitando la normalización global.\n",
    "3. **Clipping robusto**: limitar amplitudes a los percentiles [1, 99] para reducir la influencia de artefactos severos.\n",
    "4. **Ventaneo de señales**: segmentos de 5 segundos con 50% de solape; asignación de etiquetas basada en la clase dominante o presencia de S/V.\n",
    "5. **Control de fuga de información**: asegurar partición por paciente/registro en fases de entrenamiento, validación y prueba.\n",
    "\n",
    "\n",
    "\n",
    "## Próximos pasos\n",
    "\n",
    "1. Implementar el pipeline de **ventaneo con etiquetas AAMI** y exportación de **espectrogramas log-power** por canal.\n",
    "2. Construir un índice estructurado (CSV/Parquet) con **metadatos clave**: ruta, canal, clase AAMI, timestamps y parámetros de transformación espectral.\n",
    "3. Entrenar una arquitectura base **CNN ligera** (e.g., ResNet-18/EfficientNet-B0) con **class weighting y validación por sujeto**, registrando métricas clave como F1-macro y recall por clase.\n",
    "4. Aplicar técnicas de XAI (**Grad-CAM**) sobre predicciones de clases S y V para identificar **activaciones relevantes** y retroalimentar ajustes de preprocesamiento.\n",
    "5. Documentar los resultados mediante **matrices de confusión, curvas PR por clase y análisis de errores**, integrando consideraciones clínicas para una evaluación más completa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e84f216-8543-43af-b3df-3c75d9875ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
